# 缓存和Redis

## 缓存

**缓存：指数据交换的缓冲区，目的即是提升程序的读写性能。**

### 缓存算法

- LRU（最近最少使用)：新添加的数据放在头部 ，被访问到的数据放在头部，超过最大缓存量的数据将被移除。
- LFU（最不经常使用)
- FIFO（先进先出)

### 缓存常见问题

**1、缓存穿透：**指查询一个一定**不存在**的数据。

​		缓存是不命中时被动写（当从缓存中查不到数据时，然后从数据库查询到该数据，写入该数据到缓存中。），如果从 DB 查不到数据则不写入缓存。

​		**解决：**方案一，缓存空对象。当从DB查询出的数据为空，将这个空结果进行缓存并设置较短的过期时间，一般不超过五分钟。

​					方案二，布隆过滤器，即查询缓存前先根据 KEY 查询【BloomFilter 缓存】。如果不存在对应的值，直接返回；如果存在，继续向下执行。

**2、缓存雪崩**：指缓存由于某些原因无法提供服务( 例如，缓存挂掉了 )，所有请求全部达到 DB 中，导致 DB 负荷大增，最终挂掉的情况。

​	**解决：**方案一，缓存高可用（搭建集群）

​				方案二，使用本地缓存（设置较短的过期时间，保证实时性）

**3、缓存击穿：**指某个**极度“热点”**数据在某个时间点过期时，恰好在这个时间点对这个 KEY 有大量的并发请求过来，这些请求发现缓存过期一般都会从 DB 加载数据并回设到缓存。

- 和缓存“雪崩“”的区别在于，前者针对某一 KEY 缓存，后者则是很多 KEY 。
- 和缓存“穿透“”的区别在于，这个 KEY 是真实存在对应的值的。

​		**解决：**方案一，加锁，请求发现缓存不存在后，去查询 DB 前，使用分布式锁，保证有且只有一个线程去查询 DB ，并更新到缓存。

**4、缓存和 DB 的一致性如何保证**

**场景**

并发的场景下，在删除 Cache 的数据, 和更新 DB 数据时间之间有线程读取老的 DB 数据，更新到缓存中。

缓存和 DB 的操作，不在一个事务中，可能只有一个 DB 操作成功，而另一个 Cache 操作失败，导致不一致。

**解决**

- 1、将缓存可能存在的并行写，实现串行写。

> 注意，这里指的是缓存的并行写。在被动读中，如果缓存不存在，也存在写。

- 2、实现数据的最终一致性。

**方案一：**先淘汰缓存，再写数据库

因为先淘汰缓存，所以数据的最终一致性是可以得到有效的保证的。先淘汰缓存，即使写数据库发生异常，也就是下次缓存读取时，多读取一次数据库。

但是，这种方案会存在缓存和 DB 的数据会不一致的情况，那么，我们需要解决缓存并行写，实现串行写。比较简单的方式，引入分布式锁。

- 在写请求时，先淘汰缓存之前，先获取该分布式锁。
- 在读请求时，发现缓存不存在时，先获取分布式锁。

**方案二：**先写数据库，再更新缓存

按照“先写数据库，再更新缓存”，我们要保证 DB 和缓存的操作，能够在“同一个事务”中，从而实现最终一致性。

**基于定时任务来实现**

- 首先，写入数据库。
- 然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。
- 【异步】最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。



## Redis

**介绍：**是一个基于内存的高性能Key-Value数据库。

### Redis常见数据存储类型

Redis自身以key：value形式存储数据，数据存储类型指的是value，key部分永远都是字符串。

#### String：

**介绍：**通常使用字符串，如果字符串以整数的形式展示，可以作为数字操作使用

**常用命令:** `set,get,strlen,exists,dect,incr,setex` 等等。

**应用场景** ：一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。

**注意：** 数据最大存储量512M，数值计算最大范围为Java中long的最大值

#### hash:

**介绍：**hash 是一个 string 类型的 field 和 value 的映射表，适合用于存储对象,底层使用哈希表结构实现数据存储

**常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。

**应用场景:** 系统中对象数据的存储。

**注意：**hash类型下的value只能存储字符串

#### list：

**介绍：**保存多个数据，底层使用双向链表存储结构实现，支持双向添加，查找。

**常用命令:** `rpush,lpop,lpush,rpop,lrange、llen` 等。

**应用场景:** 发布与订阅或者说消息队列、慢查询。

**注意：**list中保存的数据都是string类型的，ist具有索引的概念，但是操作数据时通常以队列的形式进行入队出队操作，或以栈的形式进行入栈出栈操作 ， 获取全部数据操作结束索引设置为-1

#### set：

**介绍 ：** set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。set 提供了判断某个成员是否在一个 set 集合内的重要接口，可以基于 set 轻易实现交集、并集、差集的操作

**常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。

**应用场景:** 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

**注意：**与hash存储结构完全相同，仅存储键，不存储值（nil）

#### sorted set

**介绍：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。

**常用命令：** `zadd,zcard,zscore,zrange,zrevrange,zrem` 等。

**应用场景：** 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。

**注意：**score保存的数据存储空间是64位，score保存的数据也可以是一个双精度的double值，基于双精度浮点数的特征，可能会丢失精度，使用时 候要慎重  sorted_set 如果重复添加相同的数据，score值将被反 复覆盖，保留最后一次修改的结果

###

### Redis的线程模型

Redis 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 Socket 。
- IO 多路复用程序。
- 文件事件分派器。
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。

多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理

### Redis 单线程模型效率高原因

- 1、C 语言实现。
- 2、纯内存操作。
- 3、基于非阻塞的 IO 多路复用机制。
- 4、单线程，避免了多线程的频繁上下文切换问题。

### 持久化

**RDB---AOF：记录数据---记录数据产生的过程**

**方式一：** **RDB**【全量】持久化，将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据

**RDB启动方式：**

- save指令：会阻塞直到RDB过程完成
- bgsave指令：手工启动后台保存操作，不是立即执行
  - 客户端执行`bgsave`,返回`Background saving started`消息，接下来调用fork函数生成子进程，创建.rdb文件
- save配置：满足限定时间范围内key的变化数量达到指定数量即进行持久化（使用的bgsave）

**方式二：** **AOF**【增量】持久化，将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程

**AOF写数据三种策略(appendfsync)：**

- always(每次） 每次写入操作均同步到AOF文件中，数据零误差，性能较低
- everysec（每秒） 每秒将缓冲区中的指令同步到AOF文件中，数据准确性较高，性能较高
- no（系统控制） 由操作系统控制每次同步到AOF文件的周期

**AOF重写：** 将对同一个数据的若干个条命令执行结果转化成最终结果数据对应的指令进行记录。

**选择：**不要仅仅使用RDB那样会丢失数据，也不要仅仅使用AOF，没有RDB恢复速度来的快

### 事务

`multi` 开启事务,设定事务的开启位置，此指令执行后，后续的所有指令均加入到事务中

`exec` 执行事务,设定事务的结束位置，同时执行事务。与multi成对出现，成对使用

加入事务的命令暂时进入到任务队列中，并没有立即执行，只有执行exec命令才开始执行

`discard` 取消事务

**注意：**如果有某一条命令执行失败，其后的命令仍然会被继续执行。

### 分布式锁

`setnx` 获取锁

`expire ` 设置超时自动释放锁

### 删除策略

**过期数据：**

内存中的数据可以通过TTL指令获取其状态

- XX：具有时效性的数据

- -1：永久有效的数据
- -2 ：已经过期的数据 或 被删除的数据 或 未定义的数据

**数据删除策略：**

- 定时删除：创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作
- 惰性删除：数据到达过期时间，不做处理。等下次访问该数据时  如果未过期，返回数据  发现已过期，删除，返回不存在
- 定期删除：周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度

**数据淘汰策略：**

- 检测易失数据（可能会过期的数据集server.db[i].expires ）

  - ① volatile-lru：挑选最近最少使用的数据淘汰
  - ② volatile-lfu：挑选最近使用次数最少的数据淘汰
  - ③ volatile-ttl：挑选将要过期的数据淘汰
  - ④ volatile-random：任意选择数据淘汰

- 检测全库数据（所有数据集server.db[i].dict ）

  - ⑤ allkeys-lru：挑选最近最少使用的数据淘汰
  - ⑥ allkeys-lfu：挑选最近使用次数最少的数据淘汰
  - ⑦ allkeys-random：任意选择数据淘汰

- 放弃数据驱逐

  - ⑧ no-enviction（驱逐）：禁止驱逐数据（redis4.0中默认策略），会引发错误OOM（Out Of Memory）

**LRU算法**

LRU：最近最少使用，底层结构是hash表+双向链表。GET操作时，若节点存在，将该节点移动到链表头部，返回节点值；PUT操作时，若节点存在，更新节点并放到链表头部，若节点不存在，新增节点到链表头部。

**近似LRU算法**

-首次淘汰：随机抽样选出【最多N个数据】放入【待淘汰数据池 evictionPoolEntry】

-再次淘汰：随机抽样选出【最多N个数据】，只要数据比【待淘汰数据池 evictionPoolEntry】中的【任意一条】数据的 lru 小，则将该数据填充至 【待淘汰数据池】

-执行淘汰：挑选【待淘汰数据池】中 lru 最小的一条数据进行淘汰

### Redis 高级数据类型

- HyperLogLog： 应用于独立信息统计 （用于进行基数（数据集去重后个数）统计，不是集合，不保存数据，只记录数量而不是具体数据）
- Geo：应用于地理位置计算（设置坐标点，计算坐标点距离及范围内数据）
- Bitmap：应用于信息状态统计（对key按位进行交、并、非、或操作）

### 主从复制

主从复制即将master中的数据即时、有效的复制到slave中

**特征：**一个master可以拥有多个slave，一个slave只对应一个master

**职责： **

- master:  写数据  执行写操作时，将出现变化的数据自动同步到slave  读数据（可忽略）
-  slave:  读数据  写数据（禁止）

**过程：**

- 建立连接阶段（即准备阶段）

  slave保存master的IP与端口，创建连接maste的socket，master保存slave的端口

- 数据同步阶段

  初次连接master后，复制master中的所有数据到slave

  - 全量复制：接收master的RDB，清空数据，执行RDB文件恢复过程
  - 部分复制：接收master的缓冲区信息，执行bgrewriteaof，恢复数据

  master保存slave当前数据同步的位置

- 命令传播阶段

  master与slave间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线

### 哨兵机制

**哨兵：** 是一个分布式系统，用于对主从结构中的每台服务器进行监控，当出现故障时通过投票机制选择新的 master并将所有slave连接到新的master。

### 缓存预热

缓存预热就是系统启动前，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓 存的问题！用户直接查询事先被预热的缓存数据！

解决方案

前置准备工作： 1. 日常例行统计数据访问记录，统计访问频度较高的热点数据 2. 利用LRU数据删除策略，构建数据留存队列 例如：storm与kafka配合

准备工作： 1. 将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据 2. 利用分布式多服务器同时进行数据读取，提速数据加载过程 3. 热点数据主从同时预热

实施： 1. 使用脚本程序固定触发数据预热过程 2. 如果条件允许，使用了CDN（内容分发网络），效果会更好

### 缓存雪崩

短时间内大量key过期

**解决**

1. LRU与LFU切换
2. 数据有效期策略调整  根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟  过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量
3. 超热数据使用永久key
4. 定期维护（自动+人工） 对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时

### 缓存击穿

缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中redis后，发起了大量对同一数据的数据库访问

**解决：**

1. 预先设定 以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长 注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势
2. 现场调整 监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key
3. 后台刷新数据 启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失
4. 二级缓存 设置不同的失效时间，保障不会被同时淘汰就行

### 缓存穿透

缓存击穿访问了不存在的数据，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力

**解决**

1. 缓存null 对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟
2. 白名单策略  提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时，放 行，加载异常数据时直接拦截（效率偏低）  使用布隆过滤器（有关布隆过滤器的命中问题对当前状况可以忽略）
3. 实施监控 实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比  非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象  活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象 根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）
4. key加密 问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验 例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问